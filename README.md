# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
This dataset contains data about potential customers of a bank. E.g. the age, the profession, marital status, loan etc.

The best performing model was a

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The scikit-learn pipeline was configured with discrete values and choice parameters. While the parameter C is used for regularization, max_iter helps to define the maximum number of iterations. 

**What are the benefits of the parameter sampler you chose?**

I chose the RandomParameterSampling, which allows to define an early-stop criteria. The advantage of this parameter sampling is the reduction of cotst thanks to the early termination.

**What are the benefits of the early stopping policy you chose?**
I used the BanditPolicy, which helps to cancel poorly performing runs earlier. Via the slack factor the distance to the best performing run is calculated. If the current run is to far away form the best run, it will be stopped. This helps to save compute power, time and money. 

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

The AutoML run is configured a classification that optimizes based on the metric "Accuracy". ONNX compatible models is enabled and hence ONNX models can be exported. 

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

The accuracy of the AutoML is slightly better with the StandardScalerWrapper XGBoostClassifiera and 0.9129. The accuracy of the hyperdrive model is 0.9118361153262519.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
The data is quite imbalanced. There are techniques such as Random under-sampling or over-sampling to reduce the imbalance and to prevent overfitting on the majority class(es).

